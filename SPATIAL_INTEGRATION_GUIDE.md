# Spatial Categorization Integration Guide

## Problem with Current K-means Approach

Your current k-means in `cluster_analysis.py` (line 1136-1140) has this limitation:

```python
# Current approach - NO spatial awareness
clustered_frames, cluster_centers = process_segment_kmeans_concatenated(
    averaged_segment, n_clusters=3
)
```

**Issue**: K-means treats each pixel independently, ignoring spatial relationships:
- âŒ Isolated noise pixels get classified as "bright"
- âŒ No guarantee of spatially connected regions
- âŒ Random scattered pixels vs coherent ACh patches treated the same

---

## Solution: Spatial-Aware Methods

I've created 3 new functions in `functions/spatial_categorization.py`:

### **Option 1: Quick Replacement** â­â­â­ (RECOMMENDED)

**Simplest integration - just 2 lines:**

```python
# In cluster_analysis.py, around line 1136-1140

# OLD CODE (remove this):
# clustered_frames, cluster_centers = process_segment_kmeans_concatenated(
#     averaged_segment, n_clusters=3
# )

# NEW CODE (add this):
from functions.spatial_categorization import quick_spatial_categorize

clustered_frames = [quick_spatial_categorize(frame) for frame in averaged_segment]
```

**What it does:**
- Finds spatially connected regions (not isolated pixels)
- Filters out regions smaller than 20 pixels (noise removal)
- Categorizes by z-score thresholds (0.5 and 1.5)
- Returns same format as k-means (0, 1, 2 labels)

---

### **Option 2: Full Statistics** â­â­ (More Info)

**Get detailed region statistics:**

```python
from functions.spatial_categorization import process_segment_spatial

# Replace k-means call with:
clustered_frames, frame_stats = process_segment_spatial(
    averaged_segment,
    method='connected',
    threshold_dim=0.5,
    threshold_bright=1.5,
    min_region_size=20
)

# Now you have detailed stats:
for stat in frame_stats:
    print(f"Frame {stat['frame_idx']}: Found {stat['num_regions']} ACh regions")
    for region in stat['region_details']:
        print(f"  Region {region['region_id']}: "
              f"{region['size']} pixels, "
              f"mean z={region['mean_z']:.2f}, "
              f"category={region['category_name']}")
```

**Bonus**: You get region sizes, intensities, and can track individual ACh patches!

---

### **Option 3: Enhance Existing K-means** â­ (Minimal Change)

**Add spatial cleanup AFTER your current k-means:**

```python
from functions.spatial_categorization import categorize_spatial_morphological

# Keep your k-means:
clustered_frames, cluster_centers = process_segment_kmeans_concatenated(
    averaged_segment, n_clusters=3
)

# Add spatial cleanup:
clustered_frames_cleaned = [
    categorize_spatial_morphological(original_frame, cleanup_size=2)
    for original_frame in averaged_segment
]

# Use cleaned version for visualization:
clustered_frames = clustered_frames_cleaned
```

**What it does:**
- Runs morphological operations (erosion + dilation)
- Removes isolated pixels from k-means result
- Fills small holes in regions
- Fastest spatial method (~10ms per frame)

---

## Complete Integration Example

Here's a complete before/after for your `cluster_analysis.py`:

### **Before (Lines 1095-1140):**

```python
# ============================================================================
# K-means clustering section
# ============================================================================
console.print("\n=== K-means Clustering Analysis ===")

# Spike-triggered Averaging before k-means
min_length = min(len(seg) for seg in lst_img_segments)
target_frames = maximum_allowed_frames * 2 + 1
console.print(
    f"Minimum segment length: {min_length}, using maximum allowed frames {maximum_allowed_frames}, total {target_frames} frames"
)

# Simple averaging: take center frames from each segment
averaged_frames = []
for frame_idx in range(target_frames):
    # Collect same frame position from all segments
    frame_stack = []
    for segment in lst_img_segments:
        seg_length = len(segment)
        if seg_length >= target_frames:
            # Long enough: extract normally
            center_start = (seg_length - target_frames) // 2
            frame_stack.append(segment[center_start + frame_idx])
        else:
            # Short segment: pad into target template
            seg_center_in_target = target_frames // 2
            seg_start_in_target = seg_center_in_target - seg_length // 2

            # Check if this frame_idx falls within the segment's range
            if seg_start_in_target <= frame_idx < seg_start_in_target + seg_length:
                seg_frame_idx = frame_idx - seg_start_in_target
                frame_stack.append(segment[seg_frame_idx])

    # Average all frames at this position
    averaged_frame = np.mean(frame_stack, axis=0)
    averaged_frames.append(averaged_frame)

averaged_segment = np.array(averaged_frames)
console.print(f"Created averaged segment with shape: {averaged_segment.shape}")

# Apply k-means to averaged segment using concatenated approach
clustered_frames, cluster_centers = process_segment_kmeans_concatenated(averaged_segment, n_clusters=3)
console.print("Concatenated k-means completed on averaged data")

# Show cluster centers from concatenated analysis
console.print(f"Concatenated cluster centers: {cluster_centers}")
```

### **After (Using Spatial Method):**

```python
# ============================================================================
# Spatial Clustering Analysis (replaces k-means)
# ============================================================================
console.print("\n=== Spatial-Aware Clustering Analysis ===")

# Spike-triggered Averaging (same as before)
min_length = min(len(seg) for seg in lst_img_segments)
target_frames = maximum_allowed_frames * 2 + 1
console.print(
    f"Minimum segment length: {min_length}, using maximum allowed frames {maximum_allowed_frames}, total {target_frames} frames"
)

# Simple averaging: take center frames from each segment
averaged_frames = []
for frame_idx in range(target_frames):
    frame_stack = []
    for segment in lst_img_segments:
        seg_length = len(segment)
        if seg_length >= target_frames:
            center_start = (seg_length - target_frames) // 2
            frame_stack.append(segment[center_start + frame_idx])
        else:
            seg_center_in_target = target_frames // 2
            seg_start_in_target = seg_center_in_target - seg_length // 2

            if seg_start_in_target <= frame_idx < seg_start_in_target + seg_length:
                seg_frame_idx = frame_idx - seg_start_in_target
                frame_stack.append(segment[seg_frame_idx])

    averaged_frame = np.mean(frame_stack, axis=0)
    averaged_frames.append(averaged_frame)

averaged_segment = np.array(averaged_frames)
console.print(f"Created averaged segment with shape: {averaged_segment.shape}")

# NEW: Apply spatial-aware categorization
from functions.spatial_categorization import process_segment_spatial

clustered_frames, frame_stats = process_segment_spatial(
    averaged_segment,
    method='connected',
    threshold_dim=0.5,
    threshold_bright=1.5,
    min_region_size=20  # Filter noise
)
console.print("Spatial clustering completed on averaged data")

# Show spatial statistics
total_regions = sum(stat['num_regions'] for stat in frame_stats)
console.print(f"Found {total_regions} spatially connected ACh regions across {len(frame_stats)} frames")

# Show detailed stats for Frame 0 (spike frame)
spike_frame_idx = target_frames // 2
spike_stats = frame_stats[spike_frame_idx]
console.print(f"\nFrame 0 (spike): {spike_stats['num_regions']} regions")
for region in spike_stats['region_details']:
    console.print(
        f"  Region {region['region_id']}: {region['size']} pixels, "
        f"mean z={region['mean_z']:.2f}, {region['category_name']}"
    )
```

---

## Comparison: K-means vs Spatial Methods

| Aspect | K-means (Current) | Spatial Connected | Spatial Morphological |
|--------|-------------------|-------------------|----------------------|
| **Spatial Awareness** | âŒ No | âœ… Yes | âœ… Yes |
| **Noise Filtering** | âŒ No | âœ… Yes (min size) | âœ… Yes (erosion) |
| **Speed** | ~100ms/frame | ~50ms/frame | ~10ms/frame |
| **Region Stats** | âŒ No | âœ… Yes | âŒ No |
| **Setup** | None needed | One import | One import |
| **Parameters** | n_clusters | thresholds, min_size | thresholds, cleanup_size |

---

## Visual Comparison

Run this to see the difference:

```python
# Add this test code after line 1200 in cluster_analysis.py
from functions.spatial_categorization import compare_kmeans_vs_spatial

# Compare methods on Frame 0
frame_0_zscore = lst_img_segments_zscore[0][target_frames // 2]
comparison = compare_kmeans_vs_spatial(frame_0_zscore)

console.print(f"\n=== K-means vs Spatial Comparison ===")
console.print(f"Pixels classified differently: {comparison['difference_pixels']} "
              f"({comparison['difference_percent']:.1f}%)")
console.print(f"Spatial method found {comparison['spatial_regions']} distinct regions")

# Visualize side-by-side
fig, axes = plt.subplots(1, 3, figsize=(18, 6))

axes[0].imshow(frame_0_zscore, cmap='gray')
axes[0].set_title('Original Z-scored Frame 0')
axes[0].axis('off')

axes[1].imshow(comparison['kmeans'], cmap='viridis', vmin=0, vmax=2)
axes[1].set_title('K-means (no spatial awareness)')
axes[1].axis('off')

axes[2].imshow(comparison['spatial'], cmap='viridis', vmin=0, vmax=2)
axes[2].set_title(f'Spatial Method ({comparison["spatial_regions"]} regions)')
axes[2].axis('off')

plt.suptitle('Comparison: K-means vs Spatial Categorization')
plt.tight_layout()
plt.savefig(output_dir / f"{img_base}_kmeans_vs_spatial_comparison.png", dpi=300)
console.print(f"Saved comparison: {img_base}_kmeans_vs_spatial_comparison.png")
```

---

## Testing the New Method

### **Step 1: Test on Single Frame**

```python
# Quick test (add anywhere in your code after z-score normalization)
from functions.spatial_categorization import quick_spatial_categorize

test_frame = lst_img_segments_zscore[0][4]  # Frame 0 of first segment
categorized = quick_spatial_categorize(test_frame)

print(f"Background pixels: {np.sum(categorized == 0)}")
print(f"Dim ACh pixels: {np.sum(categorized == 1)}")
print(f"Bright ACh pixels: {np.sum(categorized == 2)}")
```

### **Step 2: Compare with Your K-means**

```bash
# In your terminal:
cd D:\MyDB\2_Programs\PG_005
python spatial_intensity_categorization.py
```

This will generate comparison figures showing the difference.

### **Step 3: Integrate into cluster_analysis.py**

Use **Option 1** (Quick Replacement) above for simplest integration.

---

## Recommended Parameters for ACh Imaging

Based on your current z-score normalization:

```python
# Good starting values:
threshold_dim = 0.5      # Pixels with z > 0.5 are potential signal
threshold_bright = 1.5   # Pixels with z > 1.5 are strong ACh release
min_region_size = 20     # Regions < 20 pixels are noise

# Adjust based on your data:
# - If too much noise: increase min_region_size to 30-50
# - If missing dim signals: lower threshold_dim to 0.3
# - If missing bright signals: lower threshold_bright to 1.0
```

---

## Troubleshooting

### **Issue**: "No regions found"
**Solution**: Lower thresholds or reduce min_region_size
```python
threshold_dim=0.3, threshold_bright=1.0, min_region_size=10
```

### **Issue**: "Too many small regions"
**Solution**: Increase min_region_size
```python
min_region_size=50  # Filter more aggressively
```

### **Issue**: "Results look similar to k-means"
**Solution**: Your ACh signals might already be spatially coherent! This is good - means your data has high SNR.

### **Issue**: "Import error"
**Solution**: Add to `functions/__init__.py`:
```python
from .spatial_categorization import (
    categorize_spatial_connected,
    categorize_spatial_morphological,
    quick_spatial_categorize
)
```

---

## Summary: Which Option Should I Use?

| If you want... | Use... |
|----------------|--------|
| **Quickest integration** | Option 1: `quick_spatial_categorize()` |
| **Detailed statistics** | Option 2: `process_segment_spatial()` |
| **Minimal code changes** | Option 3: Add morphological cleanup |
| **Test before committing** | Run comparison script first |

**My recommendation**: Start with **Option 1** - it's a 2-line change that gives you spatial awareness immediately!

---

## Next Steps

1. âœ… Read this guide
2. âœ… Run `python spatial_intensity_categorization.py` to see comparisons
3. âœ… Add Option 1 to your `cluster_analysis.py` (lines 1136-1140)
4. âœ… Run your analysis and compare results
5. âœ… Adjust parameters if needed
6. âœ… Enjoy spatially coherent ACh regions! ğŸ‰

---

*Questions? The spatial methods are in `functions/spatial_categorization.py`*
*All functions have detailed docstrings with examples.*
